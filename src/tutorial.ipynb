{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 2,
    "file_extension": ".py",
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3,
    "colab": {
      "name": "tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "oMty1YwuWHpN"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gabriel-ab/handwritten-text-recognition/blob/feat%2Fupdate-code/src/tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gP-v0E_S-mQP"
      },
      "source": [
        "<img src=\"https://github.com/arthurflor23/handwritten-text-recognition/blob/master/doc/image/header.png?raw=true\" />\n",
        "\n",
        "# Handwritten Text Recognition using TensorFlow 2.x\n",
        "\n",
        "This tutorial shows how you can use the project [Handwritten Text Recognition](https://github.com/arthurflor23/handwritten-text-recognition) in your Google Colab.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMty1YwuWHpN"
      },
      "source": [
        "## 1 Localhost Environment\n",
        "\n",
        "We'll make sure you have the project in your Google Drive with the datasets in HDF5. If you already have structured files in the cloud, skip this step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39blvPTPQJpt"
      },
      "source": [
        "### 1.1 Datasets\n",
        "\n",
        "The datasets that you can use:\n",
        "\n",
        "a. [Bentham](http://www.transcriptorium.eu/~tsdata/)\n",
        "\n",
        "b. [IAM](http://www.fki.inf.unibe.ch/databases/iam-handwriting-database)\n",
        "\n",
        "c. [Rimes](http://www.a2ialab.com/doku.php?id=rimes_database:start)\n",
        "\n",
        "d. [Saint Gall](https://fki.tic.heia-fr.ch/databases/saint-gall-database)\n",
        "\n",
        "e. [Washington](https://fki.tic.heia-fr.ch/databases/washington-database)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVBGMLifWQwl"
      },
      "source": [
        "### 1.2 Raw folder\n",
        "\n",
        "On localhost, download the code project from GitHub and extract the chosen dataset (or all if you prefer) in the **raw** folder. Don't change anything of the structure of the dataset, since the scripts were made from the **original structure** of them. Your project directory will be like this:\n",
        "\n",
        "```\n",
        ".\n",
        "├── raw\n",
        "│   ├── bentham\n",
        "│   │   ├── BenthamDatasetR0-GT\n",
        "│   │   └── BenthamDatasetR0-Images\n",
        "│   ├── iam\n",
        "│   │   ├── ascii\n",
        "│   │   ├── forms\n",
        "│   │   ├── largeWriterIndependentTextLineRecognitionTask\n",
        "│   │   ├── lines\n",
        "│   │   └── xml\n",
        "│   ├── rimes\n",
        "│   │   ├── eval_2011\n",
        "│   │   ├── eval_2011_annotated.xml\n",
        "│   │   ├── training_2011\n",
        "│   │   └── training_2011.xml\n",
        "│   ├── saintgall\n",
        "│   │   ├── data\n",
        "│   │   ├── ground_truth\n",
        "│   │   ├── README.txt\n",
        "│   │   └── sets\n",
        "│   └── washington\n",
        "│       ├── data\n",
        "│       ├── ground_truth\n",
        "│       ├── README.txt\n",
        "│       └── sets\n",
        "└── src\n",
        "    ├── data\n",
        "    │   ├── evaluation.py\n",
        "    │   ├── generator.py\n",
        "    │   ├── preproc.py\n",
        "    │   ├── reader.py\n",
        "    │   ├── similar_error_analysis.py\n",
        "    ├── main.py\n",
        "    ├── network\n",
        "    │   ├── architecture.py\n",
        "    │   ├── layers.py\n",
        "    │   ├── model.py\n",
        "    └── tutorial.ipynb\n",
        "\n",
        "```\n",
        "\n",
        "After that, create virtual environment and install the dependencies with python 3 and pip:\n",
        "\n",
        "> ```python -m venv .venv && source .venv/bin/activate```\n",
        "\n",
        "> ```pip install -r requirements.txt```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyLRbAwsWSYA"
      },
      "source": [
        "### 1.3 HDF5 files\n",
        "\n",
        "Now, you'll run the *transform* function from **main.py**. For this, execute on **src** folder:\n",
        "\n",
        "> ```python main.py --source=<DATASET_NAME> --transform```\n",
        "\n",
        "Your data will be preprocess and encode, creating and saving in the **data** folder. Now your project directory will be like this:\n",
        "\n",
        "\n",
        "```\n",
        ".\n",
        "├── data\n",
        "│   ├── bentham.hdf5\n",
        "│   ├── iam.hdf5\n",
        "│   ├── rimes.hdf5\n",
        "│   ├── saintgall.hdf5\n",
        "│   └── washington.hdf5\n",
        "├── raw\n",
        "│   ├── bentham\n",
        "│   │   ├── BenthamDatasetR0-GT\n",
        "│   │   └── BenthamDatasetR0-Images\n",
        "│   ├── iam\n",
        "│   │   ├── ascii\n",
        "│   │   ├── forms\n",
        "│   │   ├── largeWriterIndependentTextLineRecognitionTask\n",
        "│   │   ├── lines\n",
        "│   │   └── xml\n",
        "│   ├── rimes\n",
        "│   │   ├── eval_2011\n",
        "│   │   ├── eval_2011_annotated.xml\n",
        "│   │   ├── training_2011\n",
        "│   │   └── training_2011.xml\n",
        "│   ├── saintgall\n",
        "│   │   ├── data\n",
        "│   │   ├── ground_truth\n",
        "│   │   ├── README.txt\n",
        "│   │   └── sets\n",
        "│   └── washington\n",
        "│       ├── data\n",
        "│       ├── ground_truth\n",
        "│       ├── README.txt\n",
        "│       └── sets\n",
        "└── src\n",
        "    ├── data\n",
        "    │   ├── evaluation.py\n",
        "    │   ├── generator.py\n",
        "    │   ├── preproc.py\n",
        "    │   ├── reader.py\n",
        "    │   ├── similar_error_analysis.py\n",
        "    ├── main.py\n",
        "    ├── network\n",
        "    │   ├── architecture.py\n",
        "    │   ├── layers.py\n",
        "    │   ├── model.py\n",
        "    └── tutorial.ipynb\n",
        "\n",
        "```\n",
        "\n",
        "Then upload the **data** and **src** folders in the same directory in your Google Drive."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jydsAcWgWVth"
      },
      "source": [
        "## 2 Google Drive Environment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wk3e7YJiXzSl"
      },
      "source": [
        "### 2.1 TensorFlow 2.x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7twXyNGXtbJ"
      },
      "source": [
        "Make sure the jupyter notebook is using GPU mode."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHw4tODULT1Z",
        "outputId": "98fb7da1-0283-4919-b3cc-1d6d16929a49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Feb  1 14:46:53 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   74C    P8             12W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMg-B5PH9h3r",
        "outputId": "c1df5b4f-ed8d-46e8-bff5-fa2c80b972c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "if device_name != \"/device:GPU:0\":\n",
        "    raise SystemError(\"GPU device not found\")\n",
        "\n",
        "print(\"Found GPU at: {}\".format(device_name))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyMv5wyDXxqc"
      },
      "source": [
        "### 2.2 Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5gj6qwoX9W3"
      },
      "source": [
        "Mount your Google Drive partition.\n",
        "\n",
        "**Note:** *\\\"Colab Notebooks/handwritten-text-recognition/src/\\\"* was the directory where you put the project folders, specifically the **src** folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACQn1iBF9k9O",
        "outputId": "3a60c0dd-fa7f-4bd2-c8b6-91745067bfc4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%mkdir -p data\n",
        "%cp \"/content/gdrive/MyDrive/Colab Notebooks/handwritten-text-recognition/bressay.hdf5\" \"data/bressay.hdf5\""
      ],
      "metadata": {
        "id": "IVrC8Guc7nSj"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf handwritten-text-recognition/\n",
        "!git clone --branch feat/update-code https://github.com/gabriel-ab/handwritten-text-recognition.git\n",
        "\n",
        "import sys\n",
        "if '/content/handwritten-text-recognition/src/' not in sys.path:\n",
        "  sys.path.append('/content/handwritten-text-recognition/src/')"
      ],
      "metadata": {
        "id": "iF91nBXX6WaQ",
        "outputId": "28636cfa-de6c-4462-c591-b4ad3e47f788",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'handwritten-text-recognition'...\n",
            "remote: Enumerating objects: 2375, done.\u001b[K\n",
            "remote: Counting objects: 100% (2375/2375), done.\u001b[K\n",
            "remote: Compressing objects: 100% (939/939), done.\u001b[K\n",
            "remote: Total 2375 (delta 1443), reused 2328 (delta 1421), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (2375/2375), 4.89 MiB | 19.25 MiB/s, done.\n",
            "Resolving deltas: 100% (1443/1443), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YwogUA8RZAyp"
      },
      "source": [
        "After mount, you can see the list os files in the project folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fj7fSngY1IX"
      },
      "source": [
        "## 3 Set Python Classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6Q4cOlWhNl3"
      },
      "source": [
        "### 3.1 Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvqL2Eq5ZUc7"
      },
      "source": [
        "First, let's define our environment variables.\n",
        "\n",
        "Set the main configuration parameters, like input size, batch size, number of epochs and list of characters. This make compatible with **main.py** and jupyter notebook:\n",
        "\n",
        "* **dataset**: \"bentham\", \"iam\", \"rimes\", \"saintgall\", \"washington\"\n",
        "\n",
        "* **arch**: network to run: \"bluche\", \"puigcerver\", \"flor\"\n",
        "\n",
        "* **epochs**: number of epochs\n",
        "\n",
        "* **batch_size**: number size of the batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Qpr3drnGMWS",
        "outputId": "5365074f-d588-4b6e-9bb8-f2235f5b6801",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "import datetime\n",
        "import string\n",
        "\n",
        "# define parameters\n",
        "source = \"bressay\" # @param {type: \"string\"}\n",
        "arch = \"flor\" # @param {type: \"string\"}\n",
        "epochs = 1000 # @param {type: \"number\"}\n",
        "batch_size = 16 # @param {type: \"number\"}\n",
        "\n",
        "# define paths\n",
        "source_path = os.path.join(\"data\", f\"{source}.hdf5\")\n",
        "output_path = os.path.join(\"output\", source, arch)\n",
        "target_path = os.path.join(output_path, \"checkpoint_weights.hdf5\")\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "# define input size, number max of chars per line and list of valid chars\n",
        "input_size = (1024, 128, 1)\n",
        "max_text_length = 128\n",
        "charset_base = string.printable[:95]\n",
        "\n",
        "print(\"source:\", source_path)\n",
        "print(\"output\", output_path)\n",
        "print(\"target\", target_path)\n",
        "print(\"charset:\", charset_base)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "source: data/bressay.hdf5\n",
            "output output/bressay/flor\n",
            "target output/bressay/flor/checkpoint_weights.hdf5\n",
            "charset: 0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~ \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFextshOhTKr"
      },
      "source": [
        "### 3.2 DataGenerator Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfZ1mfvsanu1"
      },
      "source": [
        "The second class is **DataGenerator()**, responsible for:\n",
        "\n",
        "* Load the dataset partitions (train, valid, test);\n",
        "\n",
        "* Manager batchs for train/validation/test process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8k9vpNzMIAi2",
        "outputId": "13e4a302-a7c0-43a3-fc93-fa5c2437523a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from data.generator import DataGenerator\n",
        "\n",
        "\n",
        "dtgen = DataGenerator(source=source_path,\n",
        "                      batch_size=batch_size,\n",
        "                      charset=charset_base,\n",
        "                      max_text_length=max_text_length)\n",
        "\n",
        "print(f\"Train images: {dtgen.size['train']}\")\n",
        "print(f\"Validation images: {dtgen.size['valid']}\")\n",
        "print(f\"Test images: {dtgen.size['test']}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train images: 19565\n",
            "Validation images: 4609\n",
            "Test images: 5916\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-OdgNLK0hYAA"
      },
      "source": [
        "### 3.3 HTRModel Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHktk8AFcnKy"
      },
      "source": [
        "The third class is **HTRModel()**, was developed to be easy to use and to abstract the complicated flow of a HTR system. It's responsible for:\n",
        "\n",
        "* Create model with Handwritten Text Recognition flow, in which calculate the loss function by CTC and decode output to calculate the HTR metrics (CER, WER and SER);\n",
        "\n",
        "* Save and load model;\n",
        "\n",
        "* Load weights in the models (train/infer);\n",
        "\n",
        "* Make Train/Predict process using *generator*.\n",
        "\n",
        "To make a dynamic HTRModel, its parameters are the *architecture*, *input_size* and *vocab_size*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nV0GreStISTR",
        "outputId": "777400fd-6eb6-4322-e643-94676c08d2ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        }
      },
      "source": [
        "from network.model import HTRModel\n",
        "\n",
        "# create and compile HTRModel\n",
        "model = HTRModel(architecture=arch,\n",
        "                 input_size=input_size,\n",
        "                 vocab_size=dtgen.tokenizer.vocab_size,\n",
        "                 beam_width=10,\n",
        "                 stop_tolerance=20,\n",
        "                 reduce_tolerance=15,\n",
        "                 reduce_factor=0.1)\n",
        "\n",
        "model.compile(learning_rate=0.001)\n",
        "model.summary(output_path, \"summary.txt\")\n",
        "\n",
        "# get default callbacks and load checkpoint weights file (HDF5) if exists\n",
        "model.load_checkpoint(target=target_path)\n",
        "\n",
        "callbacks = model.get_callbacks(logdir=output_path, checkpoint=target_path, verbose=1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Unrecognized keyword arguments passed to BatchNormalization: {'renorm': True}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-e416568d386b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m                  reduce_factor=0.1)\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"summary.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/handwritten-text-recognition/src/network/model.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, learning_rate, initial_step)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;31m# define inputs, outputs and optimizer of the chosen architecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marchitecture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/handwritten-text-recognition/src/network/model.py\u001b[0m in \u001b[0;36mflor\u001b[0;34m(input_size, d_model)\u001b[0m\n\u001b[1;32m    437\u001b[0m                  padding=\"same\", kernel_initializer=\"he_uniform\")(input_data)\n\u001b[1;32m    438\u001b[0m     \u001b[0mcnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshared_axes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m     \u001b[0mcnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m     \u001b[0mcnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFullGatedConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"same\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/normalization/batch_normalization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, axis, momentum, epsilon, center, scale, beta_initializer, gamma_initializer, moving_mean_initializer, moving_variance_initializer, beta_regularizer, gamma_regularizer, beta_constraint, gamma_constraint, synchronized, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     ):\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, activity_regularizer, trainable, dtype, autocast, name, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_shape_arg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape_arg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    288\u001b[0m                 \u001b[0;34m\"Unrecognized keyword arguments \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                 \u001b[0;34mf\"passed to {self.__class__.__name__}: {kwargs}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Unrecognized keyword arguments passed to BatchNormalization: {'renorm': True}"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1fnz0Eugqru"
      },
      "source": [
        "## 4 Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1mLOcqYgsO-"
      },
      "source": [
        "The training process is similar to the *fit()* of the Keras. After training, the information (epochs and minimum loss) is save."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2P6MSoxCISlD"
      },
      "source": [
        "# to calculate total and average time per epoch\n",
        "start_time = datetime.datetime.now()\n",
        "\n",
        "h = model.fit(x=dtgen.next_train_batch(),\n",
        "              epochs=epochs,\n",
        "              steps_per_epoch=dtgen.steps['train'],\n",
        "              validation_data=dtgen.next_valid_batch(),\n",
        "              validation_steps=dtgen.steps['valid'],\n",
        "              callbacks=callbacks,\n",
        "              shuffle=True,\n",
        "              verbose=1)\n",
        "\n",
        "total_time = datetime.datetime.now() - start_time\n",
        "\n",
        "loss = h.history['loss']\n",
        "val_loss = h.history['val_loss']\n",
        "\n",
        "min_val_loss = min(val_loss)\n",
        "min_val_loss_i = val_loss.index(min_val_loss)\n",
        "\n",
        "time_epoch = (total_time / len(loss))\n",
        "total_item = (dtgen.size['train'] + dtgen.size['valid'])\n",
        "\n",
        "t_corpus = \"\\n\".join([\n",
        "    f\"Total train images:      {dtgen.size['train']}\",\n",
        "    f\"Total validation images: {dtgen.size['valid']}\",\n",
        "    f\"Batch:                   {dtgen.batch_size}\\n\",\n",
        "    f\"Total time:              {total_time}\",\n",
        "    f\"Time per epoch:          {time_epoch}\",\n",
        "    f\"Time per item:           {time_epoch / total_item}\\n\",\n",
        "    f\"Total epochs:            {len(loss)}\",\n",
        "    f\"Best epoch               {min_val_loss_i + 1}\\n\",\n",
        "    f\"Training loss:           {loss[min_val_loss_i]:.8f}\",\n",
        "    f\"Validation loss:         {min_val_loss:.8f}\"\n",
        "])\n",
        "\n",
        "with open(os.path.join(output_path, \"train.txt\"), \"w\") as lg:\n",
        "    lg.write(t_corpus)\n",
        "    print(t_corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13g7tDjWgtXV"
      },
      "source": [
        "## 5 Predict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ddO26OT-g_QK"
      },
      "source": [
        "The predict process is similar to the *predict* of the Keras:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9iHL6tmaL_j"
      },
      "source": [
        "from data import preproc as pp\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "start_time = datetime.datetime.now()\n",
        "\n",
        "# predict() function will return the predicts with the probabilities\n",
        "predicts, _ = model.predict(x=dtgen.next_test_batch(),\n",
        "                            steps=dtgen.steps['test'],\n",
        "                            ctc_decode=True,\n",
        "                            verbose=1)\n",
        "\n",
        "# decode to string\n",
        "predicts = [dtgen.tokenizer.decode(x[0]) for x in predicts]\n",
        "ground_truth = [x.decode() for x in dtgen.dataset['test']['gt']]\n",
        "\n",
        "total_time = datetime.datetime.now() - start_time\n",
        "\n",
        "# mount predict corpus file\n",
        "with open(os.path.join(output_path, \"predict.txt\"), \"w\") as lg:\n",
        "    for pd, gt in zip(predicts, ground_truth):\n",
        "        lg.write(f\"TE_L {gt}\\nTE_P {pd}\\n\")\n",
        "\n",
        "for i, item in enumerate(dtgen.dataset['test']['dt'][:10]):\n",
        "    print(\"=\" * 1024, \"\\n\")\n",
        "    cv2_imshow(pp.adjust_to_see(item))\n",
        "    print(ground_truth[i])\n",
        "    print(predicts[i], \"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JcAs3Q3WNJ-"
      },
      "source": [
        "## 6 Evaluate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LuZBRepWbom"
      },
      "source": [
        "Evaluation process is more manual process. Here we have the `ocr_metrics`, but feel free to implement other metrics instead. In the function, we have three parameters:\n",
        "\n",
        "* predicts\n",
        "* ground_truth\n",
        "* norm_accentuation (calculation with/without accentuation)\n",
        "* norm_punctuation (calculation with/without punctuation marks)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0gCwEYdKWOPK"
      },
      "source": [
        "from data import evaluation\n",
        "\n",
        "evaluate = evaluation.ocr_metrics(predicts, ground_truth)\n",
        "\n",
        "e_corpus = \"\\n\".join([\n",
        "    f\"Total test images:    {dtgen.size['test']}\",\n",
        "    f\"Total time:           {total_time}\",\n",
        "    f\"Time per item:        {total_time / dtgen.size['test']}\\n\",\n",
        "    f\"Metrics:\",\n",
        "    f\"Character Error Rate: {evaluate[0]:.8f}\",\n",
        "    f\"Word Error Rate:      {evaluate[1]:.8f}\",\n",
        "    f\"Sequence Error Rate:  {evaluate[2]:.8f}\"\n",
        "])\n",
        "\n",
        "with open(os.path.join(output_path, \"evaluate.txt\"), \"w\") as lg:\n",
        "    lg.write(e_corpus)\n",
        "    print(e_corpus)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}